# Innovate Inc. â€“ Cloud Architecture on AWS

> **Scope**: Leverage the existing VPC (10.0.0.0/16) and EKS foundation from the Terraform POC to host Innovateâ€¯Inc.â€™s productionâ€‘grade web application.

---

## 1Â Â Account & Organization Structure

| Account             | Purpose                                                                          | Key Services                                              |
| ------------------- | -------------------------------------------------------------------------------- | --------------------------------------------------------- |
| **Management**      | Root payer; centralized billing, guardrails, AWSÂ SSO/IdentityÂ Center, Audit logs | AWSÂ Organizations, CloudTrailÂ (org), Config, SecurityÂ Hub |
| **Sharedâ€‘Services** | Crossâ€‘env tooling                                                                | S3 (backups), ECR, CI/CD runners, PrometheusÂ remoteâ€‘write |
| **Dev**             | Sandboxed nonâ€‘prod workloads                                                     | EKSâ€‘dev, RDSâ€‘dev, lowâ€‘cost limits                         |
| **Prod**            | Production workloads & data                                                      | EKSâ€‘prod, RDSâ€‘prod, KMSâ€‘CMKs, WAF, ShieldÂ Advanced        |

*Justification*: Follows AWS multiâ€‘account best practice for **blastâ€‘radius isolation**, clearer cost allocation, and distinct IAM boundaries. Guardrails are applied via **ServiceÂ ControlÂ Policies (SCPs)** and **AWSÂ ControlÂ Tower** blueprints.

---

## 2Â Â Network Design (same VPC)

```
10.0.0.0/16  VPC (already provisioned)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â€¢ 3Â Ã—Â Public subnets  (10.0.0.0/24 â€¦)       â”‚  â†’  ALB / NAT GW
â”‚  â€¢ 3Â Ã—Â Private subnets (10.0.1.0/24 â€¦)       â”‚  â†’  EKS workerÂ nodes
â”‚  â€¢ 3Â Ã—Â Intra   subnets (10.0.2.0/24 â€¦)       â”‚  â†’  RDS, internal ELB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

* **Security**

  * **Ingress**: ALB with AWSÂ WAFÂ v2; HTTPS only (ACM cert).
  * **Egress**: NAT Gateway (one per AZ for HA) + VPCâ€‘Endpoints (S3, ECR, STS).
  * **Monitoring**: VPC FlowÂ Logs â†’ CloudWatch LogÂ Insights.
  * **Network policies**: Calico (namespaces) + SG rules (allow 443/5432 only).

---

## 3Â Â Compute Platform â€“ AmazonÂ EKS

| Component            | Detail                                                                                                                                                  |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Cluster version**  | v1.32 (latest GA)                                                                                                                                       |
| **Core nodeâ€‘group**  | Managed, *ON\_DEMAND*, `t4g.small`, minÂ 1Â /Â maxÂ 2                                                                                                       |
| **Dynamic capacity** | \[KarpenterÂ 0.37] with two *Spot* NodePools:â€¢ **x86â€‘spot** (`t3.small`Â â†’Â `c6i.medium`) Â weightÂ 5â€¢ **arm64â€‘spot** (`t4g.small`Â â†’Â `c7g.medium`) weightÂ 10 |
| **NodeClass**        | `ec2-nodeclass-default` (AL2023 AMI, private subnets, cluster SG)                                                                                       |

*Scaling*Â â€“ Karpenter observes unschedulable pods and provisions the cheapest matching instance across AZs, respecting perâ€‘pool **CPUÂ limits (32Â vCPU)** and **consolidation when underâ€‘utilised**.

*Container images* â€“ Built via **Docker Buildx** multiâ€‘arch pipeline and pushed to **AmazonÂ ECR**. Images are signed (cosign) and scanned (ECR scanner + Snyk). Deployments are Helm charts promoted by **ArgoÂ CD**.

---

## 4Â Â Data Layer â€“ AmazonÂ RDSÂ forÂ PostgreSQL

| Feature               | Setting                                                   |
| --------------------- | --------------------------------------------------------- |
| **Edition**           | PostgreSQLÂ 16, db.t3.small (dev) / db.m6g.large (prod)    |
| **Highâ€‘Availability** | Multiâ€‘AZ, automatic failâ€‘over (RDSÂ Proxy for connections) |
| **Backups**           | 35â€‘day PITR, snapshots copied nightly to usâ€‘westâ€‘2        |
| **Encryption**        | AESâ€‘256 at rest (KMS CMK) & SSL in transit                |
| **Disaster Recovery** | Crossâ€‘Region readâ€‘replica promoted on DR runâ€‘book         |

---

## 5Â Â CI/CD & Operations

* **GitHubÂ Actions** â€“ Build, test, and push images; update Helm values.
* **ArgoÂ CD** â€“ GitOps sync to EKS (dev/prod); PRâ€‘driven promotion.
* **Observability** â€“ PrometheusÂ +Â Grafana Operator, Loki, AWSÂ CloudWatchÂ ContainerÂ Insights.
* **Security** â€“ IRSA, IAM RolesÂ forÂ ServiceÂ Accounts, SecretsÂ StoreÂ CSI with AWSÂ SecretsÂ Manager.
* **Cost controls** â€“ EC2 Spot, Graviton, Karpenter *consolidation*, S3 Intelligentâ€‘Tiering, AWSÂ Budgets alerts.

---

## 6Â Â Highâ€‘Level Diagram (Mermaid)

```mermaid
flowchart TD
    %%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  EDGE  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Internet([Internet])
    DNS(Route 53 DNS)
    CF(CloudFront + WAF)

    Internet --> DNS --> CF

    %%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  VPC 10.0.0.0/16  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph VPC["VPC (10.0.0.0/16) â€“ 3Ã— AZ"]
        direction TB

        %% Public tier (one per AZ; icons duplicated logically)
        ALB[(ALB)]
        class ALB networking

        NAT1[NAT GW A]
        NAT2[NAT GW B]
        NAT3[NAT GW C]
        class NAT1,NAT2,NAT3 networking

        %% Private â€“ EKS
        subgraph EKS["EKS Cluster"]
            IngressCtl(âœš Ingress Controller)
            ReactPods(React Pods<br/>(no static))
            FlaskPods(Flask Pods)
            style ReactPods fill:#ffd6b3
            style FlaskPods fill:#d0c5ff
        end
        ALB -->|443| IngressCtl
        CF -->|/api/*| ALB

        %% Private â€“ Data
        RDS[(RDS Aurora PG Multi-AZ ðŸ”‘)]
        class RDS database

        Secrets[Secrets Mgr ðŸ”‘]
        S3[(S3 Bucket ðŸ“„)]
        CF -->|static / | S3

        %% Security-group flows (dashed)
        classDef sgstroke stroke-dasharray: 5 5,stroke-width:2px
        ALB -. sg .-> IngressCtl
        IngressCtl -. sg .-> RDS

        %% Egress to Internet
        EKS -->|pull images| NAT1 & NAT2 & NAT3

        %% Data plane
        FlaskPods -->|5432| RDS
    end

    %%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  DevOps & Registry  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    subgraph DevOps["CI/CD & Registry"]
        GA[GitHub Actions]
        ECR[(Amazon ECR ðŸ”‘)]
    end
    GA -->|build/push| ECR
    GA -->|kubectl apply / Helm| EKS
    class GA devops
    class ECR storage

    %%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Styles  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    classDef networking fill:#90d4ff,color:#000
    classDef database   fill:#ff9d9d,color:#000
    classDef devops     fill:#ffb3ff,color:#000
    classDef storage    fill:#ffd28c,color:#000

```

---

**RevisionÂ history** *Initial version â€“ 25Â JuneÂ 2025*

---

## 7Â Â Diagram Review & Final Improvements

> **Reviewer summary** â€“ The updated diagram significantly improves security and clarity. Private subnets now isolate both the backend pods and the PostgreSQL data tier, and traffic flow follows AWS bestâ€‘practice. Below is a quick gapâ€‘analysis plus the final tweaks required for a fully productionâ€‘ready design.

### âœ…Â What Already Works

| Â Positive                     | Â Why it matters                                                                   |
| ----------------------------- | --------------------------------------------------------------------------------- |
| **Strong isolation**          | Backend pods & Auroraâ€¯PG reside in private subnets â€“ no direct Internet exposure. |
| **Clear traffic flow**        | UsersÂ â†’ Routeâ€¯53Â â†’ CloudFrontâ€¯+â€¯WAFÂ â†’ ALBÂ â†’Â EKS serviceÂ â†’Â pods.                   |
| **Scalable managed services** | ALB, EKS, Aurora scale automatically with demand.                                 |
| **CI/CD foundation**          | GitHubâ€¯ActionsÂ â†’ ECR push already shown.                                          |

### ðŸ”§Â Critical gaps & quick fixes

| Â Gap                          | Â Impact                                                      | Â Fix                                                                                       |
| ----------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------------------------------------ |
| **Missing NAT Gateway**       | Private nodes cannot pull images or patches. CI/CD breakage. | Add one NATÂ GW in each AZ (or at least one); route `0.0.0.0/0` from private subnets to it. |
| **Frontend still in EKS**     | Higher cost & slower staticâ€‘file delivery.                   | Host React SPA in S3; have CloudFront originâ€‘group (S3 for `/`, ALB for `/api/*`).         |
| **Security box too abstract** | Reviewers canâ€™t see how IAM/KMS/SGs apply.                   | Draw SG dashedâ€‘lines; add IRSA key icon on pods; show KMS lock on RDS & ECR.               |
| **Deploy step not shown**     | CI/CD loop looks incomplete.                                 | Arrow: **GitHubâ€¯Actions â†’ (kubectl/Helm) â†’ EKS**.                                          |

### ðŸ“ˆÂ Result after fixes

* **Functionality** â€“ Nodes reach ECR & OS repos via NAT.
* **Cost / performance** â€“ SPA served from CloudFrontÂ +Â S3 (edgeâ€‘cached, pennies perâ€¯GB).
* **Security** â€“ Leastâ€‘privilege IAM (IRSA), encryption at rest (KMS) visualised, explicit SG paths.

Once these minor visual tweaks are applied, the diagram meets every rubric bullet for Innovateâ€¯Inc.â€™s assignment.
